---
title: "Unit 2 - Confidence Intervals"
subtitle: "Ma 340 Applied Statistics"
author: "Charles Lacey"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: false
    #embed-resources: true    
    smooth-scroll: true
execute:
  echo: false
  warning: false
  message: false
editor_options:
  chunk_output_type: inline
---
```{r}
# Used this if Plotly starts giving an error. 
#unlink(tempdir(), recursive = TRUE)
```



Data Import: Nursing Salary Data
```{r}
library(readr)
NursesWages <- read_csv("NursesWages.csv")
knitr::kable(NursesWages[1:10,])
```

# Estimating Population Parameters  
- **Point Estimate:** The sample statistic that is the best point estimate (or single value estimate) of the population parameter.
- **Confidence Interval:** An interval estimate of the true value of a population parameter. Abbreviated CI. 
- **Confidence Level:** The probability 1-$\alpha$ that the confidence interval actually does contain the population parameter, assuming that the estimation process is repeated a large number of times.  
- **Margin of Error:** The maximum expected difference between a sample statistic and the actual population parameter at a given confidence level.  

$$Confidence \ Interval = Point\ Estimate \pm Margin\ of\ Error = (Point\ Estimate−MoE,Point\ Estimate+MoE)$$


## Proportions  
### Point Estimate   
- What is the best point estimate for the population proportion? 
```{r}
#| echo: true
# Sample Proportion
pe = length(which(NursesWages$HighestDegreeEarned == "Master"))/nrow(NursesWages)
```
The best point estimate for the proportion of all nurses with Master degrees in 2016 is the sample proportion, $\hat{p}$ = `r round(pe, digits = 3)`, from the `r nrow(NursesWages)` nurses randomly sampled. 

### Margin of Error   
- What is the appropriate Margin of Error for $\hat{p}$?  
- What is the most likely spread of $\hat{p}$'s relative to $p$? 

##### Recall - Normal Approximation of the Binomial  
Consider the distribution of $\hat{p}$: 

$$ \hat{p} \sim N\!\left(p,\; \frac{p(1-p)}{n}\right)$$  
For $p=0.6$, 
```{r}
library(plotly)

# Parameters
p_hat <- 0.6
n <- 200
se <- sqrt(p_hat * (1 - p_hat) / n)
z <- 1.96   # 95% CI
lower <- p_hat - z * se
upper <- p_hat + z * se

# x values for curve
x <- seq(p_hat - 4*se, p_hat + 4*se, length.out = 400)
y <- dnorm(x, mean = p_hat, sd = se)

# shading region
shade_x <- x[x >= lower & x <= upper]
shade_y <- dnorm(shade_x, mean = p_hat, sd = se)

# Plot
plot_ly() |>
  add_lines(
    x = x, y = y,
    line = list(color = "blue"),
    name = "Normal Curve"
  ) |>
  add_polygons(
    x = c(shade_x, rev(shade_x)),
    y = c(shade_y, rep(0, length(shade_y))),
    fillcolor = "rgba(0,0,255,0.2)",
    line = list(color = "transparent"),
    name = "Middle 95%"
  ) |>
  layout(
    title = "Sampling Distribution of p_hat with Middle 95% Shaded",
    xaxis = list(title = "p_hat"),
    yaxis = list(title = "Density"),
    showlegend = FALSE
  )
```
More generally, for any $p$, 
$$Z = \frac{\hat{p} - p}{\sqrt{\frac{p(1-p)}{n}}} \sim N(0,1)$$

```{r}
# install.packages("plotly")  # if needed
library(plotly)

# --- Parameters ---
alpha <- 0.10                              # total alpha
alpha2 <- alpha / 2                        # per tail
zcrit  <- qnorm(1 - alpha2)                # critical value ~ 1.645 when alpha=0.10

# --- Grid for standard normal ---
x <- seq(-4, 4, length.out = 1200)
y <- dnorm(x)

# --- Tail regions for shading ---
# Left tail: (-Inf, -zcrit]
lx <- x[x <= -zcrit]
ly <- dnorm(lx)

# Right tail: [zcrit, +Inf)
rx <- x[x >= zcrit]
ry <- dnorm(rx)

# Middle region: [-zcrit, zcrit]
mx <- x[x >= -zcrit & x <= zcrit]
my <- dnorm(mx)

# --- Build plot ---
p <- plot_ly() |>
  # Normal density curve
  add_lines(
    x = x, y = y,
    line = list(color = "black", width = 3),
    name = "Standard Normal Density"
  ) |>
  # Shade left tail (alpha/2)
  add_polygons(
    x = c(lx, rev(lx)),
    y = c(ly, rep(0, length(ly))),
    fillcolor = "rgba(220, 20, 60, 0.35)",  # crimson
    line = list(color = "rgba(0,0,0,0)"),
    showlegend = FALSE
  ) |>
  # Shade right tail (alpha/2)
  add_polygons(
    x = c(rx, rev(rx)),
    y = c(ry, rep(0, length(ry))),
    fillcolor = "rgba(220, 20, 60, 0.35)",
    line = list(color = "rgba(0,0,0,0)"),
    showlegend = FALSE
  ) |>
  # Shade middle (1 - alpha)
  add_polygons(
    x = c(mx, rev(mx)),
    y = c(my, rep(0, length(my))),
    fillcolor = "rgba(30, 144, 255, 0.25)", # dodgerblue
    line = list(color = "rgba(0,0,0,0)"),
    showlegend = FALSE
  ) |>
  # Critical value lines at ±zcrit
  add_segments(
    x = -zcrit, xend = -zcrit, y = 0, yend = dnorm(-zcrit),
    line = list(color = "red", width = 3, dash = "dash"),
    showlegend = FALSE
  ) |>
  add_segments(
    x =  zcrit, xend =  zcrit, y = 0, yend = dnorm( zcrit),
    line = list(color = "red", width = 3, dash = "dash"),
    showlegend = FALSE
  ) |>
  # Labels: α/2 on each tail
  add_annotations(
    x = -zcrit - 0.25, y = dnorm(-zcrit)/4,
    text = "α/2",
    showarrow = FALSE,
    font = list(color = "black", size = 14)
  ) |>
  add_annotations(
    x =  zcrit + 0.25, y = dnorm(zcrit)/4,
    text = "α/2",
    showarrow = FALSE,
    font = list(color = "black", size = 14)
  ) |>
  # Label: 1 - α in the middle
  add_annotations(
    x = 0, y = max(dnorm(0))*0.35,
    text = "1 − α",
    showarrow = FALSE,
    font = list(color = "royalblue", size = 14)
  ) |>
  # Labels for Z_{α/2} at the critical lines
  add_annotations(
    x = -zcrit, y = dnorm(-zcrit),
    text = "-Z_α/2",
    showarrow = TRUE, arrowhead = 2, ax = -35, ay = -40,
    font = list(size = 18, color = "red")
  ) |>
  add_annotations(
    x =  zcrit, y = dnorm( zcrit),
    text = "Z_α/2",
    showarrow = TRUE, arrowhead = 2, ax =  35, ay = -40,
    font = list(size = 18, color = "red")
  ) |>
  layout(
    title = "Standard Normal Distribution",
    xaxis = list(title = "Z", range = c(-4, 4)),
    yaxis = list(visible = FALSE),
    showlegend = FALSE
  )

p
```

Since, 
$$ -z_{\alpha/2} < Z < z_{\alpha/2} $$  
$$ -z_{\alpha/2} < \frac{\hat{p} - p}{\sqrt{\frac{p(1-p)}{n}}} < z_{\alpha/2} $$  
$$ -z_{\alpha/2}*\sqrt{\frac{p(1-p)}{n}} < \hat{p} - p  < z_{\alpha/2}*\sqrt{\frac{p(1-p)}{n}} $$  
$$ -\hat{p}-z_{\alpha/2}*\sqrt{\frac{p(1-p)}{n}} <  - p  < -\hat{p} + z_{\alpha/2}*\sqrt{\frac{p(1-p)}{n}} $$  
$$ \hat{p}-z_{\alpha/2}*\sqrt{\frac{p(1-p)}{n}} <  p  < \hat{p} + z_{\alpha/2}*\sqrt{\frac{p(1-p)}{n}} $$  

Thus, $$ MoE = z_{\alpha/2}*\sqrt{\frac{\hat{p}(1-\hat{p})}{n}} $$  

### Confidence Interval  
$$ \hat{p}-z_{\alpha/2}*\sqrt{\frac{\hat{p}(1-\hat{p})}{n}} <  p  < \hat{p} + z_{\alpha/2}*\sqrt{\frac{\hat{p}(1-\hat{p})}{n}} $$  
$$ \hat{p}-MoE <  p  < \hat{p} + MoE $$  


### Example:  
#### Check Assumptions:  
```{r Check Assumptions}
#| echo: true

nrow(NursesWages)*pe 
nrow(NursesWages)*(1-pe) 
```



#### Margin of Error  
for our sample of `r nrow(NursesWages)` nurses is approximaterly, 
```{r Margin of Error}
#| echo: true

alpha = .05
MoE = -qnorm(alpha/2)*sqrt(pe*(1-pe)/nrow(NursesWages))
MoE
```
#### Confidence Interval  
```{r Confidence Interval}
#| echo: true

UB = pe + MoE
LB = pe - MoE
```
With `r (1-alpha)*100`% confidence, the actual percentage of nurses with master degrees is between `r round(LB*100, digits = 2)`% and `r round(UB*100, digits = 2)`% in 2016. 


### Base R Tools  

```{r}
#| echo: true
x = length(which(NursesWages$HighestDegreeEarned == "Master"))
n = nrow(NursesWages)

output = binom.test(x, n, conf.level = 0.95)
output$conf.int
```


## Means  
### Point Estimate   
What is the best point estimate for the population mean?  
```{r}
#| echo: true
# Sample Mean
pe = mean(NursesWages$`2016HourlyWage`)
```
The best point estimate for all hourly wages of nurses in 2016 is the sample mean of \$`r round(pe, digits = 2)` from the `r nrow(NursesWages)` nurses randomly sampled. 

### Margin of Error   
- What is the appropriate Margin of Error for $\bar{x}$?  
- What is the most likely spread of $\bar{x}$'s relative to $\mu$?

```{r}
# install.packages("plotly")  # if needed
library(plotly)

# --- Parameters ---
alpha <- 0.10                              # total alpha
alpha2 <- alpha / 2                        # per tail
zcrit  <- qnorm(1 - alpha2)                # critical value ~ 1.645 when alpha=0.10

# --- Grid for standard normal ---
x <- seq(-4, 4, length.out = 1200)
y <- dnorm(x)

# --- Tail regions for shading ---
# Left tail: (-Inf, -zcrit]
lx <- x[x <= -zcrit]
ly <- dnorm(lx)

# Right tail: [zcrit, +Inf)
rx <- x[x >= zcrit]
ry <- dnorm(rx)

# Middle region: [-zcrit, zcrit]
mx <- x[x >= -zcrit & x <= zcrit]
my <- dnorm(mx)

# --- Build plot ---
p <- plot_ly() |>
  # Normal density curve
  add_lines(
    x = x, y = y,
    line = list(color = "black", width = 3),
    name = "Standard Normal Density"
  ) |>
  # Shade left tail (alpha/2)
  add_polygons(
    x = c(lx, rev(lx)),
    y = c(ly, rep(0, length(ly))),
    fillcolor = "rgba(220, 20, 60, 0.35)",  # crimson
    line = list(color = "rgba(0,0,0,0)"),
    showlegend = FALSE
  ) |>
  # Shade right tail (alpha/2)
  add_polygons(
    x = c(rx, rev(rx)),
    y = c(ry, rep(0, length(ry))),
    fillcolor = "rgba(220, 20, 60, 0.35)",
    line = list(color = "rgba(0,0,0,0)"),
    showlegend = FALSE
  ) |>
  # Shade middle (1 - alpha)
  add_polygons(
    x = c(mx, rev(mx)),
    y = c(my, rep(0, length(my))),
    fillcolor = "rgba(30, 144, 255, 0.25)", # dodgerblue
    line = list(color = "rgba(0,0,0,0)"),
    showlegend = FALSE
  ) |>
  # Critical value lines at ±zcrit
  add_segments(
    x = -zcrit, xend = -zcrit, y = 0, yend = dnorm(-zcrit),
    line = list(color = "red", width = 3, dash = "dash"),
    showlegend = FALSE
  ) |>
  add_segments(
    x =  zcrit, xend =  zcrit, y = 0, yend = dnorm( zcrit),
    line = list(color = "red", width = 3, dash = "dash"),
    showlegend = FALSE
  ) |>
  # Labels: α/2 on each tail
  add_annotations(
    x = -zcrit - 0.25, y = dnorm(-zcrit)/4,
    text = "α/2",
    showarrow = FALSE,
    font = list(color = "black", size = 14)
  ) |>
  add_annotations(
    x =  zcrit + 0.25, y = dnorm(zcrit)/4,
    text = "α/2",
    showarrow = FALSE,
    font = list(color = "black", size = 14)
  ) |>
  # Label: 1 - α in the middle
  add_annotations(
    x = 0, y = max(dnorm(0))*0.35,
    text = "1 − α",
    showarrow = FALSE,
    font = list(color = "royalblue", size = 14)
  ) |>
  # Labels for Z_{α/2} at the critical lines
  add_annotations(
    x = -zcrit, y = dnorm(-zcrit),
    text = "-Z_α/2",
    showarrow = TRUE, arrowhead = 2, ax = -35, ay = -40,
    font = list(size = 18, color = "red")
  ) |>
  add_annotations(
    x =  zcrit, y = dnorm( zcrit),
    text = "Z_α/2",
    showarrow = TRUE, arrowhead = 2, ax =  35, ay = -40,
    font = list(size = 18, color = "red")
  ) |>
  layout(
    title = "Standard Normal Distribution",
    xaxis = list(title = "Z", range = c(-4, 4)),
    yaxis = list(visible = FALSE),
    showlegend = FALSE
  )

p
```

$$Z = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0,1)$$
$$\text{Margin of Error} = z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}$$

What is $\sigma$?

### Student t distribution  
```{r}
# install.packages("plotly")  # uncomment if needed
library(plotly)

# x-axis grid and the df values you want on the slider
x   <- seq(-5, 5, length.out = 1000)
nus <- c(1, 2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100)

# Build a long data frame with one row per (x, nu)
df <- do.call(rbind, lapply(nus, function(nu) {
  data.frame(
    x   = x,
    y   = dt(x, df = nu),
    nu  = nu
  )
}))

# Make a plotly line plot with frames = nu (drives the slider)
p <- plot_ly(
  df,
  x = ~x,
  y = ~y,
  frame = ~as.factor(nu),  # one frame per df
  type = 'scatter',
  mode = 'lines',
  name = 't',
  hovertemplate = paste(
    "x: %{x:.3f}<br>",
    "t<sub>%{frame}</sub> density: %{y:.5f}<extra></extra>"
  ),
  line = list(color = "#2C7FB8", width = 3)
) %>%
  layout(
    title = "Student-t Density with Slider for Degrees of Freedom",
    xaxis = list(title = "# of Standard Deviations"),
    yaxis = list(title = "Density"),
    margin = list(l = 60, r = 20, t = 60, b = 50)
  ) %>%
  animation_opts(
    frame = 600,  # instant switch between frames
    transition = 100,
    redraw = FALSE
  ) %>%
  animation_slider(
    currentvalue = list(prefix = "df = "),
    len = 1
  )  



# Static normal reference (same x grid)
normal_df <- data.frame(x = x, y = dnorm(x))

p <- add_lines(
  p, data = normal_df, x = ~x, y = ~y,
  line = list(color = "rgba(100,100,100,0.6)", width = 2, dash = "dash"),
  name = "N(0,1)",
  inherit = FALSE
)


p
```

$$t = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{n}}}; \ \ \ df = n-1$$
So, 
$$\text{Margin of Error} = t_{\alpha/2,\, n-1} \cdot \frac{s}{\sqrt{n}}$$

### Confidence Interval  
$$ \bar{x}-MoE <  \mu  < \bar{x} + MoE $$    


### Example:   
#### Check Assumptions:    
```{r Check Assumptions Means}
#| echo: true
nrow(NursesWages) > 30
```

#### Margin of Error  
For our sample of `r nrow(NursesWages)` nurses, Sigma is unknown.  
```{r Margin of Error Means}
#| echo: true

alpha = .05
MoE = -qt(alpha/2, nrow(NursesWages)-1) * sd(NursesWages$`2016HourlyWage`) / sqrt(nrow(NursesWages))
MoE
```

#### Confidence Interval  
```{r Confidence Interval Means}
#| echo: true

UB = pe + MoE
LB = pe - MoE
```
With `r (1-alpha)*100`% confidence, the actual average hourly salary of nurses is between \$`r round(LB, digits = 2)` and \$`r round(UB, digits = 2)` in 2016. 

### Base R Tools  
```{r}
#| echo: true
?t.test
output = t.test(NursesWages$`2016HourlyWage`, conf.level = 0.95)
output$conf.int
```

